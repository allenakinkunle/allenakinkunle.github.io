<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Allen Akinkunle | Data Science, Machine Learning</title>
    <description>The personal website of Allen Akinkunle</description>
    <link>http://allenkunle.me//</link>
    <atom:link href="http://allenkunle.me//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 14 Apr 2019 18:06:00 +0100</pubDate>
    <lastBuildDate>Sun, 14 Apr 2019 18:06:00 +0100</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Deriving Machine Learning Cost Functions using Maximum Likelihood Estimation (MLE) - Part II</title>
        <description>&lt;p&gt;In &lt;a href=&quot;/deriving-ml-cost-functions-part1&quot; target=&quot;_blank&quot;&gt;Part I&lt;/a&gt; of this article, we introduced Maximum Likelihood Estimation (MLE), Likelihood function, and derived Mean Squared Error (MSE) using Maximum likelihood estimation. In this article, we will use Maximum likelihood estimation to derive Cross-Entropy cost function, which is commonly used for binary classification problems.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;Binary logistic regression is used to model the relationship between a categorical target variable $Y$ and a predictor vector $X = (X_1, X_2, \cdots, X_p)$. The target variable will have two possible values, such as whether a student passes an exam or not, or whether a visitor to a website subscribes to the website’s newsletter or not. The two possible categories are coded as ‘1’, called the positive class, and ‘0’, called the negative class. Binary logistic regression estimates the probability that the response variable $Y$ belongs to the positive class given $X$.&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  p(X) = Pr(Y = 1 | X)
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;In linear regression, we model the expected value (the mean $\mu$) of the continuous target variable $Y$ as a linear combination of the predictor vector $X$ and estimate the weight parameters $\beta_1, \beta_2, \cdots, \beta_p$ using our training data.&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \mathbb{E}(Y|X) = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p \label{eqn:true-regression}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;In this case where our target variable $Y$ is categorical and has two possible values coded as 0 and 1, the expected value or mean of $Y$ is the probability $p(X)$ of observing the positive class&lt;sup id=&quot;fnref:expectation&quot;&gt;&lt;a href=&quot;#fn:expectation&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. It seems sensible then to model the expected value of our categorical $Y$ variable using equation \eqref{eqn:true-regression}, as in linear regression.&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \mathbb{E}(Y|X) = p(X) = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p \label{eqn:probability-linear}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;The problem with modelling the probability $p(X)$ as a linear combination of the predictor variables is that probability $p(X)$ has a range $[0, 1]$, but the right-hand side of the equation outputs values in the range $(-\infty, +\infty)$. In other words, we will get meaningless estimates of the probability if we use that equation.&lt;br /&gt;
The solution is to use a function of probability $p(X)$ that provides a suitable relationship between the linear combination of the predictor variables $X$ and $p(X)$, the mean of the response variable. This function is called a link function, and it maps the probability range $[0, 1]$ to $(-\infty, +\infty)$.&lt;br /&gt;
The most commonly used link function for binary logistic regression is the logit function (or log-odds&lt;sup id=&quot;fnref:odds&quot;&gt;&lt;a href=&quot;#fn:odds&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;), given as:&lt;/p&gt;
&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \text{logit}\bigg(p(X)\bigg) = \text{log}\bigg(\frac{p(X)}{1-p(X)}\bigg) = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p \label {eqn:logit}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;How do we then go from the logit function to getting the estimate of the probability p(X) of observing the positive class? Because logit is a function of probability, we can take its inverse to map arbitrary values in the range $(-\infty, +\infty)$ back to the probability range $[0, 1]$. &lt;br /&gt;
Recall that the inverse function of the natural logarithm function is the exponential function, so if we take the inverse of equation \eqref{eqn:logit}, we get:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \frac{p(X)}{1-p(X)} = e^{(\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p)} \label{eqn:odds}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;If we solve for $p(X)$ in equation \eqref{eqn:odds}, we get&lt;sup id=&quot;fnref:logistic&quot;&gt;&lt;a href=&quot;#fn:logistic&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  p(X) &amp;amp; = &amp;amp; \frac{e^{(\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p)}}{e^{(\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p)} + 1} \nonumber \\
      &amp;amp; = &amp;amp; \frac{1}{1 + e^{(-\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p)}} \label{eqn:logistic}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;Equation \eqref{eqn:logistic} is the logistic (or sigmoid) function, and it maps values in the logit range $(-\infty, +\infty)$ back into the range $[0, 1]$ of probabilities.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/log-odds.svg&quot; alt=&quot;log-odds&amp;amp;sigmoid&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deriving-cost-entropy-using-mle&quot;&gt;Deriving Cost Entropy using MLE&lt;/h3&gt;
&lt;p&gt;Given a set of $n$ training examples $\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(n)}, y^{(n)})\}$, binary cross-entropy is given by:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \text{Cross-Entropy} = -\bigg[\frac{1}{n} \sum_{i=1}^n\bigg(y^{(i)}\text{log} p^{(i)} + (1- y^{(i)})\text{log}(1 - p^{(i)})\bigg)\bigg] \label{eqn:cross-entropy}
\end{align} 
$$
&lt;/p&gt;

&lt;p&gt;where $x^{(i)}$ is the feature vector, $y^{(i)}$ is the true label (0 or 1) for the $i^{th}$ training example, and $p^{(i)}$ is the predicted probability that the $i^{th}$ training example belongs to the positive class, that is, $Pr(Y = 1 | X = x^{(i)})$.&lt;/p&gt;

&lt;p&gt;In this section, we will derive cross-entropy using MLE. If you are not already familiar with MLE and likelihood function, I will advise that you read the section that explains both concepts in &lt;a href=&quot;/deriving-ml-cost-functions-part1&quot;&gt;Part I&lt;/a&gt; of this article.&lt;/p&gt;

&lt;p&gt;The derivation of cross-entropy follows from using MLE to estimate the parameters $\beta_0, \beta_1, \cdots, \beta_p$ of our logistic model on our training data.&lt;br /&gt;
We start by describing the random process that generated $y^{(i)}$. &lt;br /&gt;
$y^{(i)}$ is a realisation of the Bernoulli random variable&lt;sup id=&quot;fnref:bernoulli&quot;&gt;&lt;a href=&quot;#fn:bernoulli&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; $Y$. The Bernoulli distribution is parameterised by $p$, and its probability mass function (pmf) is given by:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  Pr(Y = y^{(i)}) = \begin{cases}
   p &amp;amp; \text{if } y^{(i)} = 1, \\
   1-p &amp;amp; \text {if } y^{(i)} = 0.
 \end{cases}
\end{align} 
$$
&lt;/p&gt;

&lt;p&gt;which can be written in the more compact form:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  Pr(Y = y^{(i)}) = p^{y^{(i)}}(1-p)^{1 - y^{(i)}} \ \text{for} \ y^{(i)} \in \{0,1\} \label{eqn:compact}
\end{align} 
$$
&lt;/p&gt;

&lt;p&gt;We then define our Likelihood function. The estimates of $\beta_0, \beta_1, \cdots, \beta_p$ we choose will be the ones that maximise the likelihood function. The likelihood function is a function of our parameter $p$ given our training data:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \mathcal{L}(p | (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(n)}, y^{(n)})) &amp;amp; = \prod_{i=1}^n f(y^{(i)}|p) \nonumber \\
                                                     &amp;amp; = \prod_{i=1}^n p^{y^{(i)}}(1-p)^{1 - y^{(i)}} \label{eq:likelihood}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;It is easier to work with the log of the likelihood function&lt;sup id=&quot;fnref:part1&quot;&gt;&lt;a href=&quot;#fn:part1&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, called the log-likelihood, so if we take the natural logarithm of equation \eqref{eq:likelihood}, we get:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \log \bigg(\mathcal{L}(p | y^{(1)}, y^{(2)}, \cdots, y^{(n)})\bigg) &amp;amp; = \log\bigg( \prod_{i=1}^n p^{y^{(i)}}(1-p)^{1 - y^{(i)}} \bigg) \nonumber \\
    &amp;amp; = \sum_{i=1}^n \log \bigg(p^{y^{(i)}}(1-p)^{1 - y^{(i)}}\bigg) \nonumber \\
    &amp;amp; = \sum_{i=1}^n \bigg(y^{(i)}\text{log}p^{(i)} + (1-y^{(i)})\text{log}(1-p^{(i)})\bigg) \label{eq:log-likelihood}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;Recall that for our training data, $p^{(i)}$ in equation \eqref{eq:log-likelihood} is the predicted probability of the $i^{th}$ training example gotten from the logisitic function, so it is a function of the parameters $\beta_0, \beta_1, \cdots, \beta_p$. The maximum likelihood estimate $\hat \beta$ is therefore the value of the parameters that maximises the log-likelihood function.&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat \beta = \underset{\beta}{\operatorname{arg\,max}} \bigg[ \sum_{i=1}^n \bigg(y^{(i)}\text{log}p^{(i)} + (1-y^{(i)})\text{log}(1-p^{(i)})\bigg) \bigg]
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;We also know that maximising a function is the same as minimising its negative.&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat \beta = \underset{\beta}{\operatorname{arg\,min}} \bigg[ -\sum_{i=1}^n \bigg(y^{(i)}\text{log}p^{(i)} + (1-y^{(i)})\text{log}(1-p^{(i)})\bigg) \bigg]
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;Taking the average across our $n$ training examples, we get:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat \beta = \underset{\beta}{\operatorname{arg\,min}} \bigg[\color{red}-\frac{1}{n}\sum_{i=1}^n \bigg(y^{(i)}\text{log}p^{(i)} + (1-y^{(i)})\text{log}(1-p^{(i)})\bigg) \color{black}\bigg]
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;which is the cross-entropy as defined in equation \eqref{eqn:cross-entropy}.&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:expectation&quot;&gt;
      &lt;p&gt;$Y$ is a Bernoulli random variable. The Bernoulli distribution is a discrete probability distribution that describes processes that have only two possible outcomes: 1, with a probability of $p$ and 0, with a probability of $1 - p$. The expectation (or mean) of the Bernoulli distribution is $p$. [&lt;a href=&quot;https://brilliant.org/wiki/bernoulli-distribution/&quot; target=&quot;_blank&quot;&gt;Proof]&lt;/a&gt; &lt;a href=&quot;#fnref:expectation&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:odds&quot;&gt;
      &lt;p&gt;The odds is defined as the ratio of the probability $p$ of observing an event to the probability $1-p$ of not observing that event. $\text{odds} = \frac{p}{1-p}$. If, for example, the odds of an event happening is $o$:1, it means that the event happened $o$ times out of a total of $o+1$ occurrences. The log-odds is simply the natural logarithm of the odds. &lt;a href=&quot;#fnref:odds&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:logistic&quot;&gt;
      &lt;p&gt;A simple derivation can be found &lt;a href=&quot;https://qr.ae/TWTpnk&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; &lt;a href=&quot;#fnref:logistic&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:bernoulli&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bernoulli_distribution&quot;&gt;Bernoulli distribution&lt;/a&gt; is the discrete probability distribution of a random variable that takes on two possible values: 1 with probability $p$ and 0 with probability $1-p$. An experiment modelled by the Bernoulli distribution is called a Bernoull trial. Examples of Bernoulli trials include: tossing a coin (head/tail), playing a game (winning/not winning). &lt;a href=&quot;#fnref:bernoulli&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:part1&quot;&gt;
      &lt;p&gt;The reasons why this is the case is explained clearly in &lt;a href=&quot;/deriving-ml-cost-functions-part1&quot;&gt;Part I&lt;/a&gt;. Check the ‘What is Maximum Likelihood Estimation?’ section. &lt;a href=&quot;#fnref:part1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
        <link>http://allenkunle.me//deriving-ml-cost-functions-part2</link>
        <guid isPermaLink="true">http://allenkunle.me//deriving-ml-cost-functions-part2</guid>
        
        <category>Machine-Learning</category>
        
        
      </item>
    
      <item>
        <title>Deriving Machine Learning Cost Functions using Maximum Likelihood Estimation (MLE) - Part I</title>
        <description>&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;In supervised machine learning, cost functions are used to measure a trained model’s performance. The most commonly used cost function for regression is the Mean Squared Error (MSE), and Cross Entropy for binary classification problems. For many people, the reasons for choosing these cost functions are not at all clear.&lt;br /&gt;
The purpose of this two-part article is to shed some light on the choice of these cost functions by deriving them using Maximum Likelihood Estimation (MLE). Part I will focus on deriving MSE while &lt;a href=&quot;/deriving-ml-cost-functions-part2&quot; target=&quot;_blank&quot;&gt;Part II&lt;/a&gt; will focus on deriving Cross Entropy.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;Given a training set of $n$ examples $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots (x^{(n)}, y^{(n)})$ where $x^{(i)}$ is the feature vector for the $i^{th}$ training example and $y^{(i)}$ is its target, the goal of supervised learning is to learn a model $f: \mathcal{X} \to \mathcal{Y}$, a mapping that given $x \in \mathcal{X}$ outputs a prediction $\hat y \in \mathcal{Y}$. $\mathcal X$ and $\mathcal Y$ are called the input space and output space respectively.&lt;/p&gt;

&lt;p&gt;In order to measure how well the model fits our training data, we define a loss function. For training example $(x^{(i)}, y^{(i)})$, the loss $\mathcal{L(y^{(i)}, \hat y^{(i)})}$ measures how different the model’s prediction $\hat y^{(i)}$ is from the true label or value.
The loss is calculated for all training examples, and its average taken. This value is called the cost function and is given by:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  Cost = \frac{1}{n}\sum_{i=1}^n\mathcal{L} \bigg( y^{(i)}, \hat y^{(i)} \bigg)
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;The model $f$ usually has some unknown parameter $\theta$ (In general, $\theta$ is a vector of parameters) which we will try to estimate using the training set. We can frame supervised learning as an optimisation problem - that is, we estimate the value of $\theta$ by picking the value that minimises the cost function we chose for our problem. Let us call this parameter estimate $\hat \theta$.&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat \theta = \underset{\theta}{\operatorname{arg\,min}} \frac{1}{n}\sum_{i=1}^n\mathcal{L}\bigg(y^{(i)}, \hat y^{(i)}\bigg)
\end{align}
$$
&lt;/p&gt;

&lt;h3 id=&quot;what-is-maximum-likelihood-estimation&quot;&gt;What is Maximum Likelihood Estimation?&lt;/h3&gt;
&lt;p&gt;Maximum Likelihood Estimation (MLE) is a method of estimating the unknown parameter $\theta$ of a model, given observed data. It estimates the model parameter by finding the parameter value that maximises the likelihood function. The parameter estimate is called the maximum likelihood estimate $\hat{\theta}_{MLE}$.&lt;/p&gt;

&lt;h4 id=&quot;likelihood-function&quot;&gt;Likelihood Function&lt;/h4&gt;
&lt;p&gt;Given a set of independent and identically distributed (i.i.d)&lt;sup id=&quot;fnref:iid&quot;&gt;&lt;a href=&quot;#fn:iid&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; random variables $X_1, X_2, \cdots, X_n$ from a probability distribution $P_\theta$ with parameter $\theta$. We assume the random variables have a joint probability density function (or joint probability mass function in the case of discrete variables)&lt;sup id=&quot;fnref:jpdf&quot;&gt;&lt;a href=&quot;#fn:jpdf&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; $f(x_1, x_2,\cdots, x_n|\theta)$. Suppose $x_1, x_2,\cdots, x_n$ are the observed values of the random variables, we define the likelihood function, a function of parameter $\theta$ as:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \mathcal{L}(\theta | x_1, x_2, \cdots, x_n) = f(x_1, x_2, \cdots, x_n|\theta) \label{eq:likelihood}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;The likelihood function measures how plausible it is that the observed data was generated by the model with a particular value of $\theta$.
For example, if we use $\theta_1$ and $\theta_2$ as values of $\theta$ and find that $\mathcal{L(\theta_1 | x_1, \cdots, x_n)}$ &amp;gt; $\mathcal{L(\theta_2 | x_1, \cdots, x_n)}$, we can reasonably conclude that the observed data is more likely to have been generated by the model with its parameter being $\theta_1$.&lt;/p&gt;

&lt;p&gt;Remember that we assumed that the observed data $x_1, x_2,\cdots, x_n$ were drawn i.i.d from the probability distribution. Also recall that for independent random variables $X_1$ and $X_2$, $f(x_1,x_2|\theta) = f(x_1|\theta) \cdot f(x_2|\theta)$. Considering these, our likelihood function in equation $\eqref{eq:likelihood}$ becomes:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  \mathcal{L(\theta | x_1, x_2, \cdots, x_n)} &amp;amp; = &amp;amp; f(x_1|\theta)\cdot f(x_2|\theta)\cdots\cdot f(x_n|\theta) \nonumber \\
                                          &amp;amp; = &amp;amp; \prod_{i=1}^n f(x_i|\theta) \label{eq:likelihood-product}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;where $f(x_i|\theta)$ is the probability density (or mass for discrete variables) function of the random variable $X_i$. Since all the random variables are drawn from the same distribution, their probability density (or mass) function will be the same.&lt;/p&gt;

&lt;p&gt;It is often easier to work with the natural logarithm of the likelihood function, called the log-likelihood. Recalling the product rule of logarithms, $log(a \cdot b) = log(a) + log(b)$. If we apply the product rule to equation \eqref{eq:likelihood-product} by taking its natural logarithm, it becomes:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  \log \bigg(\mathcal{L(\theta | x_1, x_2, \cdots, x_n)}\bigg) &amp;amp; = &amp;amp; \log \bigg( f(x_1|\theta)\cdot f(x_2|\theta)\cdots\cdot f(x_n|\theta) \bigg) \nonumber \\
                                                              &amp;amp; = &amp;amp; \log(f(x_1|\theta)) + \log(f(x_2|\theta)) + \cdots + \log (f(x_n|\theta)) \nonumber \\
                                                              &amp;amp; = &amp;amp; \sum_{i=1}^n \log \bigg(f(x_i|\theta) \bigg) \label{eqn:log-likelihood}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;To find the value of $\theta$ that maximises the likelihood function, we find its critical point, the point at which the function’s derivative is $0$. That is:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \frac{\partial \mathcal{L(\theta)}}{\partial \theta} = 0
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;In most cases, this derivative is easier to compute for the log-likelihood function in equation $\eqref{eqn:log-likelihood}$ than for the vanilla likelihood function in equation $\eqref{eq:likelihood-product}$. Since logarithm is a monotononically increasing function, that is, if $x_1 &amp;gt; x_2$, then $\log(x_1) &amp;gt; log(x_2)$, the value that maximises the likelihood is also the value that maximises the log-likelihood function. &lt;br /&gt;
The other advantage of using log-likehood over likelihood is that it avoids numerical precision issues. Likelihoods are very small numbers, and taking the product of small numbers creates even smaller numbers, which can cause &lt;a href=&quot;https://en.wikipedia.org/wiki/Arithmetic_underflow&quot; target=&quot;_blank&quot;&gt;arithmetic underflow&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In other words,&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat{\theta}_{MLE} =  \underset{\theta}{\operatorname{arg\,max}}\ \mathcal L(\theta\,| x_1, \cdots, x_n)  = \underset{\theta}{\operatorname{arg\,max}}\ \log (\mathcal L(\theta\,| x_1, \cdots, x_n))
\end{align}
$$
&lt;/p&gt;

&lt;h3 id=&quot;deriving-mean-squared-errormse-using-mle&quot;&gt;Deriving Mean Squared Error(MSE) using MLE&lt;/h3&gt;
&lt;p&gt;Mean Squared Error is the cost function commonly used for regression. Given a set of $n$ traning examples of the form $(x^{(i)}, y^{(i)})$, MSE is given by:&lt;/p&gt;
&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  MSE = \frac{1}{n} \sum_{i=1}^n\bigg(y^{(i)} - \hat y^{(i)}\bigg)^2 \label{eqn:mean-s}
\end{align} 
$$
&lt;/p&gt;

&lt;p&gt;where $x^{(i)}$ is the feature vector, $y^{(i)}$ is the true output value, and $\hat y^{(i)}$ is the regression model’s prediction for the $i^{th}$ training example.&lt;/p&gt;

&lt;p&gt;In this section, we will derive MSE using maximum likelihood estimation.&lt;/p&gt;

&lt;h4 id=&quot;regression-model&quot;&gt;Regression Model&lt;/h4&gt;
&lt;p&gt;Given a vector of predictor variables $X = (X_1, X_2, \cdots X_p)$, and quantitative outcome variable $Y$, linear regression assumes that there is a linear relationship between the population mean of the outcome and the predictor variables. This relationship can be expressed by:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \mathbb{E}(Y|X) = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p \label{eqn:true-regression}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;$\mathbb{E}(Y|X)$ measures the population mean of $Y$ given a particular value of $X$ and it is often called the true regression line. Now, our observed data will not lie exactly on this true regression line. They will be spread about the true regression line. For example, if we are trying to predict height from age of a population, we will find that people of the same age will have different heights. Each person's height will differ from the population mean $\mathbb{E}(Y|X)$ by a certain amount. We represent this mathematically as:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  Y &amp;amp; = &amp;amp; \mathbb{E}(Y|X) + \epsilon \nonumber \\
    &amp;amp; = &amp;amp; \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p + \epsilon \label{eqn:regression}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;The spread about the true regression line is what the $\epsilon$ term captures. We assume it is independent of $X$ and is drawn from a Normal distribution with zero mean ($\mu$ = 0) and variance $\sigma^2$, i.e. $\epsilon \sim \mathcal{N}(0, \sigma^2)$.&lt;/p&gt;

&lt;h4 id=&quot;estimating-linear-regressions-model-parameters&quot;&gt;Estimating linear regression’s model parameters&lt;/h4&gt;
&lt;p&gt;The true regression line and its model parameters $\beta_0, \beta_1, \cdots \beta_p$ in equation \eqref{eqn:regression} are unknown, so we will try to estimate them using training data $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots (x^{(n)}, y^{(n)})$, where $x^{(i)}$ is a vector of $p$ predictor variables $(x_1, x_2, \cdots, x_p)$ and $y^{(i)}$ is the target value. Our model (the estimate of the true regression line) is:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  y^{(i)} &amp;amp; = &amp;amp; \beta_0 + \beta_1 x^{(i)}_1 + \cdots + \beta_p x^{(i)}_p + \epsilon \nonumber \\
               &amp;amp; = &amp;amp; \beta^\intercal x^{(i)} + \epsilon \nonumber \\
               &amp;amp; = &amp;amp; \hat y^{(i)} + \epsilon \label{eqn:estimate-reg}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;You will notice that $\hat y^{(i)}$ in equation \eqref{eqn:estimate-reg} is the estimate of $\mathbb{E}(Y|X)$ in equation \eqref{eqn:regression}. The $\epsilon$ term is called the residual and it measures the difference between the observed value $y^{(i)}$ and the predicted value $\hat y^{(i)}$ from the regression equation.&lt;/p&gt;

&lt;p&gt;Estimating $\beta_0, \beta_1, \cdots \beta_p$ using the training data is an optimisation problem that we can solve using MLE by defining a likelihood function. Since $\epsilon$ is normally distributed $\epsilon \sim \mathcal{N}(0, \sigma^2)$, our outcome variable $y$ will also be normally distributed. So, $y \sim \mathcal{N}(\beta^\intercal x, \sigma^2)$  The probability density function of the normal distribution (parameterised by $\mu$: mean, and $\sigma^2$: variance) is given by:&lt;/p&gt;
&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  f(y \mid \color{red}\mu, \color{black}\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2} } e^{ -\frac{(y-\color{red}\mu\color{black})^2}{2\sigma^2} } \label{eqn:pdf}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;Therefore, if we replace the parameter $\mu$ with the mean of $y$, we get:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  f(y \mid \color{red}\beta^\intercal x \color{black}, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2} } e^{ -\frac{(y-\color{red}\beta^\intercal x\color{black})^2}{2\sigma^2} } 
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;The log-likelihood function will then be:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  \log \bigg(\mathcal{L(\beta | x^{(1)}, x^{(2)}, \cdots, x^{(n)})}\bigg) &amp;amp; = &amp;amp; \sum_{i=1}^n \log \bigg( \frac{1}{\sqrt{2\pi\sigma^2} } e^{ -\frac{(y-\beta^\intercal x^{(i)})^2}{2\sigma^2} }  \bigg) \nonumber \\
                                                              &amp;amp; = &amp;amp; n \log \bigg( \frac{1}{\sqrt{2\pi\sigma^2} } \bigg) - \sum_{i=1}^n \frac{(y-\beta^\intercal x^{(i)})^2}{2\sigma^2}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;Since we need to take the derivative of log-likehood function with respect to $\beta$ to find the maximum likehood estimate of $\beta$, we can remove all the terms that do not contain our parameter $\beta$ as they do not have any effect on our optimisation &lt;sup id=&quot;fnref:remove-terms&quot;&gt;&lt;a href=&quot;#fn:remove-terms&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, so our equation becomes:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  \log \bigg(\mathcal{L(\beta | x^{(1)}, x^{(2)}, \cdots, x^{(n)})}\bigg) &amp;amp; = &amp;amp; - \sum_{i=1}^n (y-\beta^\intercal x^{(i)})^2 \nonumber \\
                                                              &amp;amp; = &amp;amp; - \sum_{i=1}^n (y-\hat y^{(i)})^2 \label{eqn:mse}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;The value of $\beta$ that maximises equation \eqref{eqn:mse} is the maximum likelihood estimate $\hat \beta_{MSE}$. That is,&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat \beta_{MSE} = \underset{\beta}{\operatorname{arg\,max}} \bigg[ -\sum_{i=1}^n(y-\hat y^{(i)})^2 \bigg] \label{eqn:maxfunc}
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;Recall that maximising a function is the same as minimising its negative, so we can rewrite equation \eqref{eqn:maxfunc} as&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{eqnarray}
  \hat \beta_{MSE} &amp;amp; = &amp;amp; \underset{\beta}{\operatorname{arg\,max}} \bigg[ -\sum_{i=1}^n(y-\hat y^{(i)})^2 \bigg] \nonumber \\
                   &amp;amp; = &amp;amp; \underset{\beta}{\operatorname{arg\,min}} \color{red}\sum_{i=1}^n(y-\hat y^{(i)})^2 \label{eqn:minfunc}
\end{eqnarray}
$$
&lt;/p&gt;

&lt;p&gt;Taking the average across all $n$ training examples, we get:&lt;/p&gt;

&lt;p class=&quot;math&quot;&gt;
$$
\begin{align}
  \hat \beta_{MSE} = \underset{\beta}{\operatorname{arg\,min}} \color{red} \frac{1}{n} \sum_{i=1}^n(y-\hat y^{(i)})^2
\end{align}
$$
&lt;/p&gt;

&lt;p&gt;which is exactly the mean squared error (MSE) cost function as defined in equation \eqref{eqn:mean-s}.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This article introduced the concept of maximum likehood estimation, likehood function, and showed the derivation of mean squared error (MSE). The second part will cover the derivation of cross entropy using maximum likelihood estimation.&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:iid&quot;&gt;
      &lt;p&gt;A set of random variables $X_1, X_2, \cdots, X_n$ are said to be independent and identically distributed if they have the same probability distribution and are mutually independent. &lt;a href=&quot;https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables&quot; target=&quot;_blank&quot;&gt;Wikipedia Article&lt;/a&gt; &lt;a href=&quot;#fnref:iid&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:jpdf&quot;&gt;
      &lt;p&gt;This &lt;a href=&quot;https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading7a.pdf&quot; target=&quot;_blank&quot;&gt;note&lt;/a&gt; from the &lt;a href=&quot;https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/&quot; target=&quot;_blank&quot;&gt;Introduction to Probability and Statistics&lt;/a&gt; class on MIT OpenCourseWare explains joint probability mass and density functions clearly. &lt;a href=&quot;#fnref:jpdf&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:remove-terms&quot;&gt;
      &lt;p&gt;The terms without the parameter $\beta$ are regarded as constants in the log-likelihood function, and differentiating a constant gives us zero. &lt;a href=&quot;#fnref:remove-terms&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
        <link>http://allenkunle.me//deriving-ml-cost-functions-part1</link>
        <guid isPermaLink="true">http://allenkunle.me//deriving-ml-cost-functions-part1</guid>
        
        <category>Machine-Learning</category>
        
        
      </item>
    
      <item>
        <title>dplyr-style Data Manipulation with Pipes in Python</title>
        <description>&lt;p&gt;I often use R’s &lt;code class=&quot;highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; package for exploratory data analysis and data manipulation. In addition to providing a consistent set of functions that one can use to solve the most common data manipulation problems, dplyr also allows one to write elegant, chainable data manipulation code using pipes.&lt;/p&gt;

&lt;p&gt;Now, Python is my main language and &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt; is my swiss army knife for data analysis, yet I often wished there was a Python package that allowed dplyr-style data manipulation directly on pandas DataFrames. I searched the Internet and found a package called &lt;code class=&quot;highlighter-rouge&quot;&gt;dfply&lt;/code&gt;, developed by &lt;a href=&quot;https://github.com/kieferk&quot; target=&quot;_blank&quot;&gt;Kiefer Katovich&lt;/a&gt;. Like dplyr, dfply also allows chaining of multiple operations with pipe operators.&lt;/p&gt;

&lt;p&gt;This post will focus on the core functions of the dfply package and show how to use them to manipulate pandas DataFrames. The complete source code and dataset is available on &lt;a href=&quot;https://github.com/allenakinkunle/dplyr-style-data-manipulation-in-python&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;getting-started&quot;&gt;Getting Started&lt;/h3&gt;
&lt;p&gt;The first thing we need to do is install the package using &lt;code class=&quot;highlighter-rouge&quot;&gt;pip&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;dfply&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;According to the project’s Github repo, dfply only works with Python 3, so ensure you have the right version of Python installed.&lt;/p&gt;

&lt;h4 id=&quot;data&quot;&gt;Data&lt;/h4&gt;
&lt;p&gt;To explore the functionality of dfply, we will use the same data used by the &lt;a href=&quot;https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html&quot; target=&quot;_blank&quot;&gt;Introduction to dplyr&lt;/a&gt; vignette. The data is from the &lt;a href=&quot;https://www.bts.gov&quot; target=&quot;_blank&quot;&gt;Bureau of Transporation Statistics&lt;/a&gt; and it contains information about all the 336,776 flights that departed from New York City in 2013.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dfply&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nycflights13.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;year&lt;/th&gt; &lt;th&gt;month&lt;/th&gt; &lt;th&gt;day&lt;/th&gt; &lt;th&gt;dep_time&lt;/th&gt; &lt;th&gt;sched_dep_time&lt;/th&gt; &lt;th&gt;dep_delay&lt;/th&gt; &lt;th&gt;arr_time&lt;/th&gt; &lt;th&gt;sched_arr_time&lt;/th&gt; &lt;th&gt;arr_delay&lt;/th&gt; &lt;th&gt;carrier&lt;/th&gt; &lt;th&gt;flight&lt;/th&gt; &lt;th&gt;tailnum&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;dest&lt;/th&gt; &lt;th&gt;air_time&lt;/th&gt; &lt;th&gt;distance&lt;/th&gt; &lt;th&gt;hour&lt;/th&gt; &lt;th&gt;minute&lt;/th&gt; &lt;th&gt;time_hour&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;0&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;517.0&lt;/td&gt;&lt;td&gt;515&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;830.0&lt;/td&gt;&lt;td&gt;819&lt;/td&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;UA&lt;/td&gt;&lt;td&gt;1545&lt;/td&gt;&lt;td&gt;N14228&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;IAH&lt;/td&gt;&lt;td&gt;227.0&lt;/td&gt;&lt;td&gt;1400&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;533.0&lt;/td&gt;&lt;td&gt;529&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;850.0&lt;/td&gt;&lt;td&gt;830&lt;/td&gt;&lt;td&gt;20.0&lt;/td&gt;&lt;td&gt;UA&lt;/td&gt;&lt;td&gt;1714&lt;/td&gt;&lt;td&gt;N24211&lt;/td&gt;&lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;IAH&lt;/td&gt;&lt;td&gt;227.0&lt;/td&gt;&lt;td&gt;1416&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;29&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;2&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;542.0&lt;/td&gt;&lt;td&gt;540&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;923.0&lt;/td&gt;&lt;td&gt;850&lt;/td&gt;&lt;td&gt;33.0&lt;/td&gt;&lt;td&gt;AA&lt;/td&gt;&lt;td&gt;1141&lt;/td&gt;&lt;td&gt;N619AA&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;MIA&lt;/td&gt;&lt;td&gt;160.0&lt;/td&gt;&lt;td&gt;1089&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;40&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;3&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;544.0&lt;/td&gt;&lt;td&gt;545&lt;/td&gt;&lt;td&gt;-1.0&lt;/td&gt;&lt;td&gt;1004.0&lt;/td&gt;&lt;td&gt;1022&lt;/td&gt;&lt;td&gt;-18.0&lt;/td&gt;&lt;td&gt;B6&lt;/td&gt;&lt;td&gt;725&lt;/td&gt;&lt;td&gt;N804JB&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;BQN&lt;/td&gt;&lt;td&gt;183.0&lt;/td&gt;&lt;td&gt;1576&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;45&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;4&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;554.0&lt;/td&gt;&lt;td&gt;600&lt;/td&gt;&lt;td&gt;-6.0&lt;/td&gt;&lt;td&gt;812.0&lt;/td&gt;&lt;td&gt;837&lt;/td&gt;&lt;td&gt;-25.0&lt;/td&gt;&lt;td&gt;DL&lt;/td&gt;&lt;td&gt;461&lt;/td&gt;&lt;td&gt;N668DN&lt;/td&gt;&lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;ATL&lt;/td&gt;&lt;td&gt;116.0&lt;/td&gt;&lt;td&gt;762&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-01 06:00:00&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;piping&quot;&gt;Piping&lt;/h3&gt;
&lt;p&gt;Let’s say you want to perform &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt; discrete transformation operations on your dataset before outputting the final result. The most common way is to perform the operations step by step and store the result of each step in a variable. The variable holding the intermediate result is then used in the next step of the transformation pipeline. Let’s take a look at an abstract example.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 'original_data' could be a pandas DataFrame.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformation_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformation_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result_3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformation_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;final_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This isn’t very elegant code and it can get confusing and messy to write. This is where piping comes to the rescue. Piping allows us to rewrite the above code without needing those intermediate variables.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;final_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;transformation_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;transformation_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;transformation_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;transformation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Magic?! No, it isn’t. Piping works by implicitly making the output of one stage the input of the following stage. In other words, each transformation step works on the transformed result of its previous step.&lt;/p&gt;

&lt;h4 id=&quot;piping-with-dfply&quot;&gt;Piping with dfply&lt;/h4&gt;
&lt;p&gt;dfply allows chaining multiple operations on a pandas DataFrame with the &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&amp;gt;&lt;/code&gt; operator. One can chain operations and assign the final output (a pandas DataFrame, since dfply works directly on DataFrames) to a variable. In dfply, the DataFrame result of each step of a chain of operations is represented by &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;. &lt;br /&gt;
For example, if you want to select three columns from a DataFrame in a step, drop the third column in the next step, and then show the first three rows of the final dataframe, you could do something like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 'data' is the original pandas DataFrame
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;third_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;third_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;select&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;drop&lt;/code&gt; are both dfply transformation functions, while &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; represents the result of each transformation step.&lt;/p&gt;

&lt;h3 id=&quot;exploring-some-of-dfplys-transformation-methods&quot;&gt;Exploring some of dfply’s transformation methods&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dfply&lt;/code&gt; provides a set of functions for selecting and dropping columns, subsetting and filtering rows, grouping data, and reshaping data, to name a few.&lt;/p&gt;

&lt;h4 id=&quot;select-and-drop-columns-with-select-and-drop&quot;&gt;Select and drop columns with &lt;code class=&quot;highlighter-rouge&quot;&gt;select()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;drop()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Occassionally, you will work on datasets with a lot of columns, but only a subset of the columns will be of interest; &lt;code class=&quot;highlighter-rouge&quot;&gt;select()&lt;/code&gt; allows you to select these columns.&lt;br /&gt;
For example, to select the &lt;code class=&quot;highlighter-rouge&quot;&gt;origin&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;dest&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;hour&lt;/code&gt; columns in the &lt;code class=&quot;highlighter-rouge&quot;&gt;flight_data&lt;/code&gt; DataFrame we loaded earlier, we do:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;dest&lt;/th&gt; &lt;th&gt;hour&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;0&lt;/th&gt; &lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;IAH&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;IAH&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;2&lt;/th&gt; &lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;MIA&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;3&lt;/th&gt; &lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;BQN&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;4&lt;/th&gt; &lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;ATL&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;drop()&lt;/code&gt; is the inverse of &lt;code class=&quot;highlighter-rouge&quot;&gt;select()&lt;/code&gt;. It returns all the columns except those passed in as arguments. &lt;br /&gt;
For example, to get all the columns except the &lt;code class=&quot;highlighter-rouge&quot;&gt;year&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;month&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;day&lt;/code&gt; columns:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can also drop columns inside the &lt;code class=&quot;highlighter-rouge&quot;&gt;select()&lt;/code&gt; method by putting a tilde &lt;code class=&quot;highlighter-rouge&quot;&gt;~&lt;/code&gt; in front of the column(s) you wish to drop.&lt;br /&gt;
For example, to select all but the &lt;code class=&quot;highlighter-rouge&quot;&gt;hour&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;minute&lt;/code&gt; columns in the &lt;code class=&quot;highlighter-rouge&quot;&gt;flight_data&lt;/code&gt; DataFrame:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;filter-rows-with-mask&quot;&gt;Filter rows with &lt;code class=&quot;highlighter-rouge&quot;&gt;mask()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mask()&lt;/code&gt; allows you to select a subset of rows in a pandas DataFrame based on logical criteria. &lt;code class=&quot;highlighter-rouge&quot;&gt;mask()&lt;/code&gt; selects all the rows where the criteria is/are true. &lt;br /&gt;
For example, to select all flights longer than 10 hours that originated from JFK airport on January 1:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'JFK'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;year&lt;/th&gt; &lt;th&gt;month&lt;/th&gt; &lt;th&gt;day&lt;/th&gt; &lt;th&gt;dep_time&lt;/th&gt; &lt;th&gt;sched_dep_time&lt;/th&gt; &lt;th&gt;dep_delay&lt;/th&gt; &lt;th&gt;arr_time&lt;/th&gt; &lt;th&gt;sched_arr_time&lt;/th&gt; &lt;th&gt;arr_delay&lt;/th&gt; &lt;th&gt;carrier&lt;/th&gt; &lt;th&gt;flight&lt;/th&gt; &lt;th&gt;tailnum&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;dest&lt;/th&gt; &lt;th&gt;air_time&lt;/th&gt; &lt;th&gt;distance&lt;/th&gt; &lt;th&gt;hour&lt;/th&gt; &lt;th&gt;minute&lt;/th&gt; &lt;th&gt;time_hour&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;151&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;848.0&lt;/td&gt;&lt;td&gt;1835&lt;/td&gt;&lt;td&gt;853.0&lt;/td&gt;&lt;td&gt;1001.0&lt;/td&gt;&lt;td&gt;1950&lt;/td&gt;&lt;td&gt;851.0&lt;/td&gt;&lt;td&gt;MQ&lt;/td&gt;&lt;td&gt;3944&lt;/td&gt;&lt;td&gt;N942MQ&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;BWI&lt;/td&gt;&lt;td&gt;41.0&lt;/td&gt;&lt;td&gt;184&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt;35&lt;/td&gt;&lt;td&gt;2013-01-01 18:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;258&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1059.0&lt;/td&gt;&lt;td&gt;1100&lt;/td&gt;&lt;td&gt;-1.0&lt;/td&gt;&lt;td&gt;1210.0&lt;/td&gt;&lt;td&gt;1215&lt;/td&gt;&lt;td&gt;-5.0&lt;/td&gt;&lt;td&gt;MQ&lt;/td&gt;&lt;td&gt;3792&lt;/td&gt;&lt;td&gt;N509MQ&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;DCA&lt;/td&gt;&lt;td&gt;50.0&lt;/td&gt;&lt;td&gt;213&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-01 11:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;265&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1111.0&lt;/td&gt;&lt;td&gt;1115&lt;/td&gt;&lt;td&gt;-4.0&lt;/td&gt;&lt;td&gt;1222.0&lt;/td&gt;&lt;td&gt;1226&lt;/td&gt;&lt;td&gt;-4.0&lt;/td&gt;&lt;td&gt;B6&lt;/td&gt;&lt;td&gt;24&lt;/td&gt;&lt;td&gt;N279JB&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;BTV&lt;/td&gt;&lt;td&gt;52.0&lt;/td&gt;&lt;td&gt;266&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;2013-01-01 11:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;266&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1112.0&lt;/td&gt;&lt;td&gt;1100&lt;/td&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;1440.0&lt;/td&gt;&lt;td&gt;1438&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;UA&lt;/td&gt;&lt;td&gt;285&lt;/td&gt;&lt;td&gt;N517UA&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;SFO&lt;/td&gt;&lt;td&gt;364.0&lt;/td&gt;&lt;td&gt;2586&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-01 11:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;272&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1124.0&lt;/td&gt;&lt;td&gt;1100&lt;/td&gt;&lt;td&gt;24.0&lt;/td&gt;&lt;td&gt;1435.0&lt;/td&gt;&lt;td&gt;1431&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;B6&lt;/td&gt;&lt;td&gt;641&lt;/td&gt;&lt;td&gt;N590JB&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;SFO&lt;/td&gt;&lt;td&gt;349.0&lt;/td&gt;&lt;td&gt;2586&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-01 11:00:00&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&quot;sort-rows-with-arrange&quot;&gt;Sort rows with &lt;code class=&quot;highlighter-rouge&quot;&gt;arrange()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;arrange()&lt;/code&gt; allows you to order rows based on one or multiple columns; the default behaviour is to sort the rows in ascending order. &lt;br /&gt;
For example, to sort by &lt;code class=&quot;highlighter-rouge&quot;&gt;distance&lt;/code&gt; and then by the number of &lt;code class=&quot;highlighter-rouge&quot;&gt;hours&lt;/code&gt; the flights take, we do:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;year&lt;/th&gt; &lt;th&gt;month&lt;/th&gt; &lt;th&gt;day&lt;/th&gt; &lt;th&gt;dep_time&lt;/th&gt; &lt;th&gt;sched_dep_time&lt;/th&gt; &lt;th&gt;dep_delay&lt;/th&gt; &lt;th&gt;arr_time&lt;/th&gt; &lt;th&gt;sched_arr_time&lt;/th&gt; &lt;th&gt;arr_delay&lt;/th&gt; &lt;th&gt;carrier&lt;/th&gt; &lt;th&gt;flight&lt;/th&gt; &lt;th&gt;tailnum&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;dest&lt;/th&gt; &lt;th&gt;air_time&lt;/th&gt; &lt;th&gt;distance&lt;/th&gt; &lt;th&gt;hour&lt;/th&gt; &lt;th&gt;minute&lt;/th&gt; &lt;th&gt;time_hour&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;275945&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;27&lt;/td&gt;&lt;td&gt;NaN&lt;/td&gt;&lt;td&gt;106&lt;/td&gt;&lt;td&gt;NaN&lt;/td&gt;&lt;td&gt;NaN&lt;/td&gt;&lt;td&gt;245&lt;/td&gt;&lt;td&gt;NaN&lt;/td&gt;&lt;td&gt;US&lt;/td&gt;&lt;td&gt;1632&lt;/td&gt;&lt;td&gt;NaN&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;NaN&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;2013-07-27 01:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;3083&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1240.0&lt;/td&gt;&lt;td&gt;1200&lt;/td&gt;&lt;td&gt;40.0&lt;/td&gt;&lt;td&gt;1333.0&lt;/td&gt;&lt;td&gt;1306&lt;/td&gt;&lt;td&gt;27.0&lt;/td&gt;&lt;td&gt;EV&lt;/td&gt;&lt;td&gt;4193&lt;/td&gt;&lt;td&gt;N14972&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;PHL&lt;/td&gt;&lt;td&gt;30.0&lt;/td&gt;&lt;td&gt;80&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-04 12:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;3901&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;1155.0&lt;/td&gt;&lt;td&gt;1200&lt;/td&gt;&lt;td&gt;-5.0&lt;/td&gt;&lt;td&gt;1241.0&lt;/td&gt;&lt;td&gt;1306&lt;/td&gt;&lt;td&gt;-25.0&lt;/td&gt;&lt;td&gt;EV&lt;/td&gt;&lt;td&gt;4193&lt;/td&gt;&lt;td&gt;N14902&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;PHL&lt;/td&gt;&lt;td&gt;29.0&lt;/td&gt;&lt;td&gt;80&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-05 12:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;3426&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1829.0&lt;/td&gt;&lt;td&gt;1615&lt;/td&gt;&lt;td&gt;134.0&lt;/td&gt;&lt;td&gt;1937.0&lt;/td&gt;&lt;td&gt;1721&lt;/td&gt;&lt;td&gt;136.0&lt;/td&gt;&lt;td&gt;EV&lt;/td&gt;&lt;td&gt;4502&lt;/td&gt;&lt;td&gt;N15983&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;PHL&lt;/td&gt;&lt;td&gt;28.0&lt;/td&gt;&lt;td&gt;80&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;2013-01-04 16:00:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;10235&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;1613.0&lt;/td&gt;&lt;td&gt;1617&lt;/td&gt;&lt;td&gt;-4.0&lt;/td&gt;&lt;td&gt;1708.0&lt;/td&gt;&lt;td&gt;1722&lt;/td&gt;&lt;td&gt;-14.0&lt;/td&gt;&lt;td&gt;EV&lt;/td&gt;&lt;td&gt;4616&lt;/td&gt;&lt;td&gt;N11150&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;PHL&lt;/td&gt;&lt;td&gt;36.0&lt;/td&gt;&lt;td&gt;80&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;2013-01-12 16:00:00&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To sort in descending order, you set the &lt;code class=&quot;highlighter-rouge&quot;&gt;ascending&lt;/code&gt; keyword argument of &lt;code class=&quot;highlighter-rouge&quot;&gt;arrange()&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;, like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;add-new-columns-with-mutate&quot;&gt;Add new columns with &lt;code class=&quot;highlighter-rouge&quot;&gt;mutate()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mutate()&lt;/code&gt; allows you to create new columns in the DataFrame. The new columns can be composed from existing columns.&lt;br /&gt;
For example, let’s create two new columns: one by dividing the &lt;code class=&quot;highlighter-rouge&quot;&gt;distance&lt;/code&gt; column by &lt;code class=&quot;highlighter-rouge&quot;&gt;1000&lt;/code&gt;, and the other by concatenating the &lt;code class=&quot;highlighter-rouge&quot;&gt;carrier&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;origin&lt;/code&gt; columns. We will name these new columns &lt;code class=&quot;highlighter-rouge&quot;&gt;new_distance&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;carrier_origin&lt;/code&gt; respectively.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;new_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;carrier_origin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;year&lt;/th&gt; &lt;th&gt;month&lt;/th&gt; &lt;th&gt;day&lt;/th&gt; &lt;th&gt;dep_time&lt;/th&gt; &lt;th&gt;sched_dep_time&lt;/th&gt; &lt;th&gt;dep_delay&lt;/th&gt; &lt;th&gt;arr_time&lt;/th&gt; &lt;th&gt;sched_arr_time&lt;/th&gt; &lt;th&gt;arr_delay&lt;/th&gt; &lt;th&gt;carrier&lt;/th&gt; &lt;th&gt;...&lt;/th&gt; &lt;th&gt;tailnum&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;dest&lt;/th&gt; &lt;th&gt;air_time&lt;/th&gt; &lt;th&gt;distance&lt;/th&gt; &lt;th&gt;hour&lt;/th&gt; &lt;th&gt;minute&lt;/th&gt; &lt;th&gt;time_hour&lt;/th&gt; &lt;th&gt;carrier_origin&lt;/th&gt; &lt;th&gt;new_distance&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;0&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;517.0&lt;/td&gt;&lt;td&gt;515&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;830.0&lt;/td&gt;&lt;td&gt;819&lt;/td&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;UA&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;N14228&lt;/td&gt;&lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;IAH&lt;/td&gt;&lt;td&gt;227.0&lt;/td&gt;&lt;td&gt;1400&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;td&gt;UAEWR&lt;/td&gt;&lt;td&gt;1.400&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;533.0&lt;/td&gt;&lt;td&gt;529&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;850.0&lt;/td&gt;&lt;td&gt;830&lt;/td&gt;&lt;td&gt;20.0&lt;/td&gt;&lt;td&gt;UA&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;N24211&lt;/td&gt;&lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;IAH&lt;/td&gt;&lt;td&gt;227.0&lt;/td&gt;&lt;td&gt;1416&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;29&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;td&gt;UALGA&lt;/td&gt;&lt;td&gt;1.416&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;2&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;542.0&lt;/td&gt;&lt;td&gt;540&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt;923.0&lt;/td&gt;&lt;td&gt;850&lt;/td&gt;&lt;td&gt;33.0&lt;/td&gt;&lt;td&gt;AA&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;N619AA&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;MIA&lt;/td&gt;&lt;td&gt;160.0&lt;/td&gt;&lt;td&gt;1089&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;40&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;td&gt;AAJFK&lt;/td&gt;&lt;td&gt;1.089&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;3&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;544.0&lt;/td&gt;&lt;td&gt;545&lt;/td&gt;&lt;td&gt;-1.0&lt;/td&gt;&lt;td&gt;1004.0&lt;/td&gt;&lt;td&gt;1022&lt;/td&gt;&lt;td&gt;-18.0&lt;/td&gt;&lt;td&gt;B6&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;N804JB&lt;/td&gt;&lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;BQN&lt;/td&gt;&lt;td&gt;183.0&lt;/td&gt;&lt;td&gt;1576&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;45&lt;/td&gt;&lt;td&gt;2013-01-01 05:00:00&lt;/td&gt;&lt;td&gt;B6JFK&lt;/td&gt;&lt;td&gt;1.576&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;4&lt;/th&gt; &lt;td&gt;2013&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;554.0&lt;/td&gt;&lt;td&gt;600&lt;/td&gt;&lt;td&gt;-6.0&lt;/td&gt;&lt;td&gt;812.0&lt;/td&gt;&lt;td&gt;837&lt;/td&gt;&lt;td&gt;-25.0&lt;/td&gt;&lt;td&gt;DL&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;N668DN&lt;/td&gt;&lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;ATL&lt;/td&gt;&lt;td&gt;116.0&lt;/td&gt;&lt;td&gt;762&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2013-01-01 06:00:00&lt;/td&gt;&lt;td&gt;DLLGA&lt;/td&gt;&lt;td&gt;0.762&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The newly created columns will be at the end of the DataFrame.&lt;/p&gt;

&lt;h4 id=&quot;group-and-ungroup-data-with-group_by-and-ungroup&quot;&gt;Group and ungroup data with &lt;code class=&quot;highlighter-rouge&quot;&gt;group_by()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ungroup()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;group_by()&lt;/code&gt; allows you to group the DataFrame by one or multiple columns. Functions chained after &lt;code class=&quot;highlighter-rouge&quot;&gt;group_by()&lt;/code&gt; are applied on the group until the DataFrame is ungrouped with the &lt;code class=&quot;highlighter-rouge&quot;&gt;ungroup()&lt;/code&gt; function. For example, to group the data by the originating airport, we do:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;summarise-data-using-summarize&quot;&gt;Summarise data using &lt;code class=&quot;highlighter-rouge&quot;&gt;summarize()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;summarize()&lt;/code&gt; is typically used together with &lt;code class=&quot;highlighter-rouge&quot;&gt;group_by()&lt;/code&gt; to reduce each group into a single row summary. In other words, the output will have one row for each group. For example, to calculate the mean distance for flights originating from every airport, we do:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;mean_distance&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;0&lt;/th&gt; &lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;1056.742790&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;1266.249077&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;2&lt;/th&gt; &lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;779.835671&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&quot;bringing-it-all-together-with-pipes&quot;&gt;Bringing it all together with pipes&lt;/h3&gt;
&lt;p&gt;Let’s say you want to perform the following operations on the flights data&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;[Step 1]: Filter out all flights less than 10 hours&lt;/li&gt;
  &lt;li&gt;[Step 2]: Create a new column, &lt;code class=&quot;highlighter-rouge&quot;&gt;speed&lt;/code&gt;, using the formula [distance / (air time * 60)]&lt;/li&gt;
  &lt;li&gt;[Step 3]: Calculate the mean speed for flights originating from each airport&lt;/li&gt;
  &lt;li&gt;[Step 4]: Sort the result by mean speed in descending order&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will write the operations using &lt;code class=&quot;highlighter-rouge&quot;&gt;dfply&lt;/code&gt; piping operator &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&amp;gt;&lt;/code&gt;. We won’t have to use intermediate variables to save the result of each step.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# step 1
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;air_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# step 2
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# step 3a
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_speed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# step 3b
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_speed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# step 4
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;table&quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;origin&lt;/th&gt; &lt;th&gt;mean_speed&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;0&lt;/th&gt; &lt;td&gt;EWR&lt;/td&gt;&lt;td&gt;0.109777&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td&gt;JFK&lt;/td&gt;&lt;td&gt;0.109427&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;2&lt;/th&gt; &lt;td&gt;LGA&lt;/td&gt;&lt;td&gt;0.107362&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;If we use &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt; data manipulation functions instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;dfply&lt;/code&gt;’s, our code will look something like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hour'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'speed'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'distance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'air_time'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flight_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'origin'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'speed'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'speed'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;I find the &lt;code class=&quot;highlighter-rouge&quot;&gt;dfply&lt;/code&gt; version easier to read and understand than the &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt; version.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This is by no means an exhaustive coverage of the functionality of the &lt;code class=&quot;highlighter-rouge&quot;&gt;dfply&lt;/code&gt; package. The &lt;a href=&quot;https://github.com/kieferk/dfply&quot; target=&quot;_blank&quot;&gt;package documentation&lt;/a&gt; is really good and I advise that you check it out to learn more.&lt;/p&gt;

&lt;p&gt;If you have suggestions or questions, please drop a comment in the comment section below. You can also send me an email at hello [at] allenkunle [dot] me or tweet at me &lt;a href=&quot;https://twitter.com/allenakinkunle&quot; target=&quot;_blank&quot;&gt;@allenakinkunle&lt;/a&gt;, and I will reply as soon as I can.&lt;/p&gt;

&lt;p&gt;The complete source code for this blog post is available on &lt;a href=&quot;https://github.com/allenakinkunle/dplyr-style-data-manipulation-in-python&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;. Thank you for reading, and please don’t forget to share.&lt;/p&gt;

</description>
        <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
        <link>http://allenkunle.me//dplyr-style-data-manipulation-in-python</link>
        <guid isPermaLink="true">http://allenkunle.me//dplyr-style-data-manipulation-in-python</guid>
        
        <category>Python</category>
        
        <category>pandas</category>
        
        <category>dplyr</category>
        
        <category>Data-Wrangling</category>
        
        
      </item>
    
      <item>
        <title>Exploratory Analysis of the Washington's Post Police Shooting dataset using R and Plotly</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://www.washingtonpost.com/graphics/national/police-shootings-2016/&quot; target=&quot;_blank&quot;&gt;Washington Post&lt;/a&gt; has been compiling a database of fatal shootings in the United States by police officers in the line of duty since January 1, 2015. The &lt;a href=&quot;https://github.com/washingtonpost/data-police-shootings&quot; target=&quot;_blank&quot;&gt;dataset&lt;/a&gt; contains information such as the date and the state in which the killing occurred, the age, gender and, race of the deceased.&lt;/p&gt;

&lt;p&gt;In light of the recent Police killings in the US, I thought it would be interesting to perform the following exploratory analyses using the dataset:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The distribution of the deceased by age group&lt;/li&gt;
  &lt;li&gt;The distribution of Police killings per million people for each state using a choropleth map.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will use R and &lt;a href=&quot;https://plot.ly&quot; target=&quot;_blank&quot;&gt;Plotly&lt;/a&gt; for this purpose.&lt;/p&gt;

&lt;h3 id=&quot;required-packages&quot;&gt;Required Packages&lt;/h3&gt;
&lt;p&gt;For this analysis, we will need the &lt;code class=&quot;highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; package for data manipulation, the &lt;code class=&quot;highlighter-rouge&quot;&gt;magrittr&lt;/code&gt; package for pipe-like operations, and the &lt;code class=&quot;highlighter-rouge&quot;&gt;plotly&lt;/code&gt; package for creating interactive graphs. Install these packages using R’s &lt;code class=&quot;highlighter-rouge&quot;&gt;install.packages&lt;/code&gt; method if you haven’t already, then load the packages using the &lt;code class=&quot;highlighter-rouge&quot;&gt;library&lt;/code&gt; method.&lt;/p&gt;

&lt;p&gt;The complete source code for this post is available on &lt;a href=&quot;https://github.com/allenakinkunle/washington-post-data-analysis&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;data-preparation&quot;&gt;Data Preparation&lt;/h3&gt;
&lt;p&gt;The first thing we need to do is read the data into R as a dataframe from where it is hosted on Github.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/fatal-police-shootings-data.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;colnames()&lt;/code&gt; method to get the column names of the data frame.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;date&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;manner_of_death&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;        
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;armed&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                   &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;age&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;gender&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;race&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                   
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                   &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;signs_of_mental_illness&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;threat_level&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;           
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;flee&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;                    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;body_camera&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We see that there are 14 variables. We only need the &lt;code class=&quot;highlighter-rouge&quot;&gt;age&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt; variables for our analysis so we use &lt;code class=&quot;highlighter-rouge&quot;&gt;dplyr&lt;/code&gt;’s &lt;code class=&quot;highlighter-rouge&quot;&gt;select()&lt;/code&gt; method to create a new data frame with only those variables selected. Remember that you can always check out a method’s documentation in R using &lt;code class=&quot;highlighter-rouge&quot;&gt;?method_name&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Let’s see what the new dataframe looks like&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;47&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OR&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KS&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;39&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CO&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OK&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The age column contains integer values and the state column contains the 2-letter abbreviations for the states in which the killings occurred.&lt;/p&gt;

&lt;h3 id=&quot;handling-missing-values&quot;&gt;Handling Missing Values&lt;/h3&gt;
&lt;p&gt;Before performing any analysis, it’s a good practice to check for anomalies like missing values in the data. Missing values are coded with &lt;code class=&quot;highlighter-rouge&quot;&gt;NA&lt;/code&gt; in most datasets, so we check for this in our dataset. Be familiar with how missing values are represented in your dataset and handle them accordingly.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;is.na&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;sapply()&lt;/code&gt; method applies the function supplied as its argument to each column of the data frame. The function returns the number of cells that have &lt;code class=&quot;highlighter-rouge&quot;&gt;NA&lt;/code&gt; as their values in each of the dataframe’s column. To learn more about the Apply family of functions in R, check this &lt;a href=&quot;https://www.datacamp.com/community/tutorials/r-tutorial-apply-family&quot; target=&quot;_blank&quot;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We see that there are 37 missing values coded as &lt;code class=&quot;highlighter-rouge&quot;&gt;NA&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;age&lt;/code&gt; column so we handle this by recoding them to &lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt;. The choice of 0 will be apparent in the following section.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;is.na&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;how-many-people-are-killed-by-age-group&quot;&gt;How many people are killed by age group?&lt;/h3&gt;
&lt;p&gt;Since the ages are integer values, I thought it would be more useful to group them and then plot the distribution of killings in the age groups. We convert the integer values into categories (factors) using the &lt;code class=&quot;highlighter-rouge&quot;&gt;cut()&lt;/code&gt; method. Running &lt;code class=&quot;highlighter-rouge&quot;&gt;?cut&lt;/code&gt; in R, we get the following documentation:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cut&lt;/code&gt; divides the range of x into intervals and codes the values in x according to which interval they fall. The leftmost interval corresponds to level one, the next leftmost to level two and so on.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;Inf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;Inf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Unknown&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Under 18&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;18-29&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;30-44&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;45-59&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;60 above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Since we coded our missing age values as 0, we set the label for any value between -Inf and 1 to &lt;em&gt;“Unknown”&lt;/em&gt;. This interval covers our missing values coded as 0. Ages between 1 and 18 are grouped into &lt;em&gt;“Under 18”&lt;/em&gt;, 18 - 30 coded as &lt;em&gt;“18-29”&lt;/em&gt;, 30 - 45 coded as &lt;em&gt;“30-44”&lt;/em&gt;, 45 - 60 coded as &lt;em&gt;“45 - 59”&lt;/em&gt; while ages between 60 and Inf are coded as &lt;em&gt;“60 above”&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In the following code snippet, we group the data frame by the age group categories column &lt;code class=&quot;highlighter-rouge&quot;&gt;cat_age&lt;/code&gt; we created above and then summarise each group by counting the number of killings. We pass the summarised data into ggplot and display it as a bar chart.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;killings_by_age_group_plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;identity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#f29999&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Age Group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Number of Police Killings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Distribution of Police Killings by age group in the United States (Jan 2015 - July 2016)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplotly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;killings_by_age_group_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Make graph interactive with Plotly&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The reason Plotly was chosen for this analysis is because it allows us to create beautiful, interactive visualisation with APIs in Python, R and many other languages. The &lt;code class=&quot;highlighter-rouge&quot;&gt;ggplotly&lt;/code&gt; method accepts a &lt;code class=&quot;highlighter-rouge&quot;&gt;ggplot&lt;/code&gt; object as argument and turns it into an interactive graph. Check out &lt;a href=&quot;https://plot.ly/r/#basic-charts&quot; target=&quot;_blank&quot;&gt;some example plots&lt;/a&gt; created with Plotly’s R library.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;%&amp;gt;%&lt;/code&gt; operator in the snippet above might look strange to some R users. &lt;code class=&quot;highlighter-rouge&quot;&gt;%&amp;gt;%&lt;/code&gt;, available in the &lt;code class=&quot;highlighter-rouge&quot;&gt;magrittr&lt;/code&gt; package, allows us to pipe values into an expression or a function call. It improves code readability by removing the need to create a bunch of variables to hold the results of function calls. Check out &lt;a href=&quot;https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html&quot; target=&quot;_blank&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;magrittr&lt;/code&gt;’s vignette&lt;/a&gt; for a detailed explanation of how to use the package.&lt;/p&gt;

&lt;div class=&quot;plotly&quot;&gt;
  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://plot.ly/~allenkunle/0.embed&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The plot is interactive so hover and click on it to interact with it.&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-police-killings-per-million-population-value-for-each-state&quot;&gt;What is the Police killings per million population value for each state?&lt;/h3&gt;
&lt;p&gt;To compare the number of police killings across US states in our dataset, we will compute the police killings per million population value for each state and plot these values on a &lt;code class=&quot;highlighter-rouge&quot;&gt;Plotly&lt;/code&gt;’s choropleth map.&lt;/p&gt;

&lt;p&gt;For this analysis, we need the population estimates for each state and the full state names. These details are not in the Washington Post’s dataset so we need to get them from other sources. We will use the &lt;code class=&quot;highlighter-rouge&quot;&gt;state.abb&lt;/code&gt; (contains the 2-letter state name abbreviations) and &lt;code class=&quot;highlighter-rouge&quot;&gt;state.name&lt;/code&gt; (contains the full state names) datasets available in R to get the full state names into our &lt;code class=&quot;highlighter-rouge&quot;&gt;shooting_data&lt;/code&gt; dataframe.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt; data sets contain information relating to the 50 states of the US and they are arranged according to alphabetical order of the state names. So for an index &lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;, the 2-letter state name abbreviation at &lt;code class=&quot;highlighter-rouge&quot;&gt;state.abb[i]&lt;/code&gt; will map to the full state name at &lt;code class=&quot;highlighter-rouge&quot;&gt;state.name[i]&lt;/code&gt;. One caveat of the &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt; datasets is that they do not contain information about the District of Columbia.&lt;/p&gt;

&lt;p&gt;For the population estimates of each state, I created a state population data set from data I extracted from the &lt;a href=&quot;https://www.census.gov/popest/data/state/totals/2015/index.html&quot; target=&quot;_blank&quot;&gt;United States Census Bureau website&lt;/a&gt;. I have cleaned the data set and it contains 2015 population estimates for each of the 50 US states and the District of Columbia. The data set is hosted &lt;a href=&quot;https://raw.githubusercontent.com/allenakinkunle/washington-post-data-analysis/master/state_population_data.csv&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We start our analysis by adding the full state name for each row containing the 2-letter state name abbreviation in our dataframe. We check for matches between the values of our &lt;code class=&quot;highlighter-rouge&quot;&gt;shooting_data$state&lt;/code&gt; column and the &lt;code class=&quot;highlighter-rouge&quot;&gt;state.abb&lt;/code&gt; vector. If there is a match, the &lt;code class=&quot;highlighter-rouge&quot;&gt;match()&lt;/code&gt; method returns the index of the match in the &lt;code class=&quot;highlighter-rouge&quot;&gt;state.abb&lt;/code&gt; vector, else it returns &lt;code class=&quot;highlighter-rouge&quot;&gt;NA&lt;/code&gt;, in this case this only happens for &lt;strong&gt;DC&lt;/strong&gt; (District of Columbia) abbreviation.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_name&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Get full state name if index exists, else set full state name as &quot;District of Columbia&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state.abb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_name&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifelse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;is.na&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;District of Columbia&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state.name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Let’s take a look into how the dataframe looks now&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_name&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;45-59&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Washington&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;47&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OR&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;45-59&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Oregon&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KS&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;18-29&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Kansas&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We see that the full state name has been added to the dataframe. To get the population estimates for each state, we read in the state population data set.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;state_population_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://raw.githubusercontent.com/allenakinkunle/washington-post-data-analysis/master/state_population_data.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In the following code snippet, we group the data frame by state name and count the number of killings in each state. We use &lt;code class=&quot;highlighter-rouge&quot;&gt;merge()&lt;/code&gt; to perform an inner join of our &lt;code class=&quot;highlighter-rouge&quot;&gt;shooting_data&lt;/code&gt;  dataframe and newly imported &lt;code class=&quot;highlighter-rouge&quot;&gt;state_population_data&lt;/code&gt; dataframe by their common column &lt;code class=&quot;highlighter-rouge&quot;&gt;state_name&lt;/code&gt;. We then use &lt;code class=&quot;highlighter-rouge&quot;&gt;dplyr&lt;/code&gt;’s &lt;code class=&quot;highlighter-rouge&quot;&gt;mutate&lt;/code&gt; method to add the computed Police killings per million for each state to the dataframe. The &lt;code class=&quot;highlighter-rouge&quot;&gt;hover&lt;/code&gt; variable, also added to the dataframe, is used by &lt;code class=&quot;highlighter-rouge&quot;&gt;Plotly&lt;/code&gt; to display a hover text when the choropleth map is interacted with.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;killings_by_state&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shooting_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_population_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;state_name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# calculate the killings per million for each state&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;killings_per_million&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;population&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hover&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;br&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;killings_per_million&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'per million people'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;br&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'shootings since January 2015'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The next step is to use &lt;code class=&quot;highlighter-rouge&quot;&gt;Plotly&lt;/code&gt;’s &lt;code class=&quot;highlighter-rouge&quot;&gt;plot_ly&lt;/code&gt; method to create the choropleth map. We pass in the &lt;code class=&quot;highlighter-rouge&quot;&gt;killings_by_state&lt;/code&gt; dataframe we created above as argument to the function among other configuration arguments.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# List of options for the map&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toRGB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;white&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scope&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'usa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Plot the choropleth map&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_ly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;killings_by_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;killings_per_million&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hover&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;locations&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'choropleth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;locationmode&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'USA-states'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;killings_per_million&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Reds'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colorbar&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Police killings per million people&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lenmode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;pixels&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titleside&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;right&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xpad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ypad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Police killings per million people in United States (Jan 2015 - July 2016))'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;plotly&quot;&gt;
  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://plot.ly/~allenkunle/2.embed&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Hover on the map, zoom in and out to interact with it.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This blog post shows the power of R for quick exploratory analysis and demonstrates how static graphs can be brought to life with Plotly. Plotly is easy to use for users familiar with &lt;code class=&quot;highlighter-rouge&quot;&gt;ggplot&lt;/code&gt; as it uses a similar syntax. If you have suggestions or questions, please drop a comment in the comment section below. You can  also send me emails at hello [at] allenkunle [dot] me or tweet at me &lt;a href=&quot;https://twitter.com/allenakinkunle&quot; target=&quot;_blank&quot;&gt;@allenakinkunle&lt;/a&gt;, and I will reply as soon as I can.&lt;/p&gt;

&lt;p&gt;The complete source code is available on &lt;a href=&quot;https://github.com/allenakinkunle/washington-post-data-analysis&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;. Feel free to check and make suggestions for improvements. Thank you for reading!&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jul 2016 00:00:00 +0100</pubDate>
        <link>http://allenkunle.me//exploratory-analysis-police-shooting</link>
        <guid isPermaLink="true">http://allenkunle.me//exploratory-analysis-police-shooting</guid>
        
        <category>R</category>
        
        <category>Plotly</category>
        
        
      </item>
    
  </channel>
</rss>
